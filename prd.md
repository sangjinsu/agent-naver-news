# ë„¤ì´ë²„ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ìš”ì•½ ì—ì´ì „íŠ¸ PRD

## 1. í”„ë¡œì íŠ¸ ê°œìš”

### 1.1 í”„ë¡œì íŠ¸ëª…

Naver News Headlines Summarizer Agent

### 1.2 ëª©ì 

ë„¤ì´ë²„ ë‰´ìŠ¤ì˜ ì£¼ìš” ì¹´í…Œê³ ë¦¬ë³„ í—¤ë“œë¼ì¸ ë‰´ìŠ¤ë¥¼ ìë™ìœ¼ë¡œ ìˆ˜ì§‘í•˜ê³  ìš”ì•½í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ì œê³µí•˜ëŠ” LangGraph ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ êµ¬ì¶•

### 1.3 ëŒ€ìƒ ì¹´í…Œê³ ë¦¬

- ì •ì¹˜
- ê²½ì œ
- ì‚¬íšŒ
- ìƒí™œ/ë¬¸í™”
- IT/ê³¼í•™
- ì„¸ê³„

## 2. ê¸°ìˆ  ìŠ¤íƒ

### 2.1 í•„ìˆ˜ ìš”êµ¬ì‚¬í•­

- **Python**: 3.12+
- **íŒ¨í‚¤ì§€ ê´€ë¦¬ì**: uv
- **í”„ë ˆì„ì›Œí¬**: LangGraph 0.6+
- **LLM**: OpenAI API (GPT-4o-mini ë˜ëŠ” GPT-4o)

### 2.2 ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬

```toml
# pyproject.toml
[project]
name = "naver-news-agent"
version = "0.1.0"
requires-python = ">=3.12"
dependencies = [
    "langgraph>=0.6.0",
    "langchain-core>=0.3.0",
    "langchain-openai>=0.2.0",
    "beautifulsoup4>=4.12.0",
    "httpx>=0.27.0",
    "pydantic>=2.0.0",
    "python-dotenv>=1.0.0",
    "rich>=13.0.0",  # for better markdown display in terminal
]
```

## 3. ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ (LangGraph 0.6+)

### 3.1 ì—ì´ì „íŠ¸ êµ¬ì¡°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   StateGraph        â”‚
â”‚   (LangGraph 0.6)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
     â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
     â”‚   START   â”‚
     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
           â”‚
     â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
     â”‚  Scraper  â”‚
     â”‚   Node    â”‚
     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
           â”‚
     â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
     â”‚ Summarizerâ”‚
     â”‚   Node    â”‚
     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
           â”‚
     â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
     â”‚ Formatter â”‚
     â”‚   Node    â”‚
     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
           â”‚
     â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
     â”‚    END    â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 LangGraph 0.6+ ì£¼ìš” ì»´í¬ë„ŒíŠ¸

#### 3.2.1 State Definition

```python
from typing import Annotated, List, Dict
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages

class NewsAgentState(TypedDict):
    """LangGraph 0.6+ ì–´ë…¸í…Œì´ì…˜ì´ í¬í•¨ëœ ìƒíƒœ"""
    categories: List[str]
    raw_news: Annotated[List[Dict], "ìŠ¤í¬ë˜í•‘ëœ ì›ë³¸ ë‰´ìŠ¤ ë°ì´í„°"]
    summaries: Annotated[List[Dict], "ì¹´í…Œê³ ë¦¬ë³„ ìš”ì•½ëœ ë‰´ìŠ¤"]
    final_markdown: Annotated[str, "ìµœì¢… ë§ˆí¬ë‹¤ìš´ ì¶œë ¥"]
    errors: Annotated[List[str], "ì—ëŸ¬ ë©”ì‹œì§€"]
```

#### 3.2.2 Graph Builder (LangGraph 0.6+ ìŠ¤íƒ€ì¼)

```python
from langgraph.graph import StateGraph
from langgraph.prebuilt import ToolNode
from langgraph.checkpoint.memory import MemorySaver

# ìƒíƒœë¥¼ ì‚¬ìš©í•œ ê·¸ë˜í”„ ì´ˆê¸°í™”
workflow = StateGraph(NewsAgentState)

# ë…¸ë“œ ì¶”ê°€
workflow.add_node("scraper", scraper_node)
workflow.add_node("summarizer", summarizer_node)
workflow.add_node("formatter", formatter_node)

# ì—£ì§€ ì¶”ê°€
workflow.add_edge(START, "scraper")
workflow.add_edge("scraper", "summarizer")
workflow.add_edge("summarizer", "formatter")
workflow.add_edge("formatter", END)

# ìƒíƒœ ì˜ì†ì„±ì„ ìœ„í•œ ì²´í¬í¬ì¸í„°ì™€ í•¨ê»˜ ì»´íŒŒì¼
memory = MemorySaver()
app = workflow.compile(checkpointer=memory)
```

#### 3.2.3 ë…¸ë“œ êµ¬í˜„ íŒ¨í„´

```python
async def scraper_node(state: NewsAgentState) -> NewsAgentState:
    """LangGraph 0.6+ íŒ¨í„´ì„ ì‚¬ìš©í•œ ìŠ¤í¬ë˜í¼ ë…¸ë“œ"""
    # êµ¬í˜„
    return {"raw_news": scraped_data}

async def summarizer_node(state: NewsAgentState) -> NewsAgentState:
    """OpenAI í†µí•© ìš”ì•½ ë…¸ë“œ"""
    # êµ¬í˜„
    return {"summaries": summarized_data}
```

## 4. ë°ì´í„° ëª¨ë¸ (LangGraph 0.6+ Compatible)

### 4.1 News Article Schema

```python
from pydantic import BaseModel, Field
from datetime import datetime
from typing import Optional, List, Annotated

class NewsArticle(BaseModel):
    """ê°œë³„ ë‰´ìŠ¤ ê¸°ì‚¬ ëª¨ë¸"""
    title: str
    url: str
    summary: Optional[str] = None
    category: str
    scraped_at: datetime = Field(default_factory=datetime.now)

class CategoryNews(BaseModel):
    """ì¹´í…Œê³ ë¦¬ë³„ ë‰´ìŠ¤ ì»¬ë ‰ì…˜"""
    category: str
    articles: List[NewsArticle]
    summary_markdown: str = ""

class NewsReport(BaseModel):
    """ìµœì¢… ë‰´ìŠ¤ ë¦¬í¬íŠ¸ ëª¨ë¸"""
    generated_at: datetime = Field(default_factory=datetime.now)
    categories: List[CategoryNews]
    full_markdown: str
```

### 4.2 LangGraph 0.6+ State

```python
from typing import TypedDict, List, Annotated
from langgraph.graph.message import AnyMessage

class NewsAgentState(TypedDict):
    """LangGraph 0.6+ìš© ìƒíƒœ ìŠ¤í‚¤ë§ˆ"""
    # ì…ë ¥
    categories: List[str]

    # ì²˜ë¦¬ ë‹¨ê³„
    raw_news: Annotated[List[dict], "ìŠ¤í¬ë˜í•‘ëœ ì›ë³¸ ë‰´ìŠ¤"]
    summaries: Annotated[List[dict], "ì¹´í…Œê³ ë¦¬ë³„ ìš”ì•½"]

    # ì¶œë ¥
    final_markdown: Annotated[str, "ìµœì¢… ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸"]

    # ë©”íƒ€ë°ì´í„°
    messages: Annotated[List[AnyMessage], "ì²˜ë¦¬ ë©”ì‹œì§€"]
    errors: Annotated[List[str], "ì—ëŸ¬ ì¶”ì "]
    timestamp: Annotated[str, "ì²˜ë¦¬ íƒ€ì„ìŠ¤íƒ¬í”„"]
```

## 5. í•µì‹¬ ê¸°ëŠ¥

### 5.1 ë‰´ìŠ¤ ìˆ˜ì§‘ (Scraping)

- ê° ì¹´í…Œê³ ë¦¬ í˜ì´ì§€ ì ‘ê·¼
- í—¤ë“œë¼ì¸ ì„¹ì…˜ ì‹ë³„ ë° íŒŒì‹±
- ë°˜ë³µ ì‹¤í–‰ì„ ìœ„í•œ ìŠ¤ì¼€ì¤„ë§ ì§€ì›

### 5.2 ë‰´ìŠ¤ ìš”ì•½ (Summarization with OpenAI)

- OpenAI GPT-4o-mini ë˜ëŠ” GPT-4o ì‚¬ìš©
- ì¹´í…Œê³ ë¦¬ë³„ ì¤‘ìš”ë„ ê¸°ë°˜ ë‰´ìŠ¤ ì„ ë³„
- í•œêµ­ì–´ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§
- Markdown í˜•ì‹ ìš”ì•½ ìƒì„±

### 5.3 Markdown ì¶œë ¥ í˜•ì‹

```markdown
# ğŸ“° ë„¤ì´ë²„ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ìš”ì•½

> ìƒì„± ì‹œê°: 2024-XX-XX HH:MM:SS

## ğŸ›ï¸ ì •ì¹˜

### ì£¼ìš” ë‰´ìŠ¤

1. **[ì œëª©]** - í•µì‹¬ ë‚´ìš© ìš”ì•½
2. **[ì œëª©]** - í•µì‹¬ ë‚´ìš© ìš”ì•½

### ì˜¤ëŠ˜ì˜ í¬ì¸íŠ¸

- ì£¼ìš” ì´ìŠˆ ì •ë¦¬

## ğŸ’° ê²½ì œ

### ì£¼ìš” ë‰´ìŠ¤

1. **[ì œëª©]** - í•µì‹¬ ë‚´ìš© ìš”ì•½
2. **[ì œëª©]** - í•µì‹¬ ë‚´ìš© ìš”ì•½

### ì˜¤ëŠ˜ì˜ í¬ì¸íŠ¸

- ì‹œì¥ ë™í–¥ ë° ì£¼ìš” ì§€í‘œ

[ì´í•˜ ì¹´í…Œê³ ë¦¬ë³„ ë™ì¼ í˜•ì‹]
```

### 5.4 ê²°ê³¼ ì €ì¥

- Markdown íŒŒì¼ ì €ì¥ (`output/YYYY-MM-DD_news_summary.md`)
- í„°ë¯¸ë„ ì¶œë ¥ (Rich ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš©)
- ì„ íƒì  GitHub Gist ì—…ë¡œë“œ

## 6. í”„ë¡œì íŠ¸ êµ¬ì¡° ë° ì½”ë”© ê·œì¹™

### 6.1 í”„ë¡œì íŠ¸ êµ¬ì¡°

```
naver-news-agent/
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ .env
â”œâ”€â”€ README.md
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ orchestrator.py
â”‚   â”‚   â””â”€â”€ graph.py
â”‚   â”œâ”€â”€ nodes/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ scraper.py
â”‚   â”‚   â””â”€â”€ summarizer.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ schemas.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ config.py
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_scraper.py
â”‚   â””â”€â”€ test_summarizer.py
â””â”€â”€ output/
    â””â”€â”€ reports/
```

### 6.2 ì½”ë”© ê·œì¹™

- **ì£¼ì„ ì–¸ì–´**: ëª¨ë“  ì£¼ì„ì€ í•œê¸€ë¡œ ì‘ì„±
- **Docstring**: í•œê¸€ë¡œ ì‘ì„±, Google Style ì‚¬ìš©
- **ë³€ìˆ˜ëª…**: ì˜ì–´ ì‚¬ìš©, snake_case
- **í´ë˜ìŠ¤ëª…**: ì˜ì–´ ì‚¬ìš©, PascalCase
- **ìƒìˆ˜**: ì˜ì–´ ì‚¬ìš©, UPPER_SNAKE_CASE

### 6.3 ì£¼ì„ ì‘ì„± ì˜ˆì‹œ

```python
# ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘ì„ ìœ„í•œ ê¸°ë³¸ í´ë˜ìŠ¤
class NewsScraper:
    """
    ë„¤ì´ë²„ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ì„ ìŠ¤í¬ë˜í•‘í•˜ëŠ” í´ë˜ìŠ¤

    Attributes:
        base_url: ë„¤ì´ë²„ ë‰´ìŠ¤ ê¸°ë³¸ URL
        categories: ìŠ¤í¬ë˜í•‘í•  ì¹´í…Œê³ ë¦¬ ëª©ë¡
    """

    def __init__(self):
        # ê¸°ë³¸ ì„¤ì • ì´ˆê¸°í™”
        self.base_url = "https://news.naver.com"
        # ì¹´í…Œê³ ë¦¬ë³„ URL ë§¤í•‘
        self.categories = {
            "ì •ì¹˜": "/section/100",
            "ê²½ì œ": "/section/101"
        }

    async def scrape_headlines(self, category: str) -> List[NewsArticle]:
        """
        íŠ¹ì • ì¹´í…Œê³ ë¦¬ì˜ í—¤ë“œë¼ì¸ ë‰´ìŠ¤ë¥¼ ìŠ¤í¬ë˜í•‘

        Args:
            category: ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ (ì˜ˆ: "ì •ì¹˜", "ê²½ì œ")

        Returns:
            NewsArticle ê°ì²´ ë¦¬ìŠ¤íŠ¸

        Raises:
            ScrapingError: ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨ ì‹œ
        """
        # ì¹´í…Œê³ ë¦¬ URL ìƒì„±
        url = f"{self.base_url}{self.categories[category]}"

        # HTTP ìš”ì²­ ì „ì†¡
        # ...
```

## 7. êµ¬í˜„ ë‹¨ê³„

### Phase 1: ê¸°ë³¸ ì„¤ì • (Week 1)

- [ ] í”„ë¡œì íŠ¸ ì´ˆê¸°í™” (uv init)
- [ ] ì˜ì¡´ì„± ì„¤ì¹˜ ë° í™˜ê²½ ì„¤ì •
- [ ] ê¸°ë³¸ í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„±

### Phase 2: í¬ë¡¤ëŸ¬ ê°œë°œ (Week 1-2)

- [ ] ë„¤ì´ë²„ ë‰´ìŠ¤ HTML êµ¬ì¡° ë¶„ì„
- [ ] Scraper Node êµ¬í˜„
- [ ] ì¹´í…Œê³ ë¦¬ë³„ í…ŒìŠ¤íŠ¸

### Phase 3: LangGraph ì—ì´ì „íŠ¸ êµ¬í˜„ (Week 2-3)

- [ ] Graph ìƒíƒœ ì •ì˜
- [ ] Node ì—°ê²° ë° í”Œë¡œìš° êµ¬í˜„
- [ ] Orchestrator ë¡œì§ ê°œë°œ

### Phase 4: OpenAI ìš”ì•½ ê¸°ëŠ¥ ê°œë°œ (Week 3)

- [ ] OpenAI API ì—°ë™ ì„¤ì •
- [ ] Markdown ìƒì„± í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§
- [ ] Summary Node êµ¬í˜„
- [ ] ë¹„ìš© ìµœì í™” (GPT-4o-mini vs GPT-4o ì„ íƒ ë¡œì§)

### Phase 5: í†µí•© ë° í…ŒìŠ¤íŠ¸ (Week 4)

- [ ] ì „ì²´ íŒŒì´í”„ë¼ì¸ í†µí•©
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±
- [ ] ì„±ëŠ¥ ìµœì í™”

### Phase 6: ë°°í¬ ì¤€ë¹„ (Week 4)

- [ ] ë¬¸ì„œí™”
- [ ] Docker ì»¨í…Œì´ë„ˆí™” (ì„ íƒ)
- [ ] ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì • (cron/airflow)

## 8. í™˜ê²½ ë³€ìˆ˜

```env
# .env
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o-mini  # ë˜ëŠ” gpt-4o

# Optional
USER_AGENT="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
REQUEST_DELAY=1.0  # seconds between requests
OUTPUT_DIR=./output/reports
```

## 9. ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­

- ì „ì²´ ì¹´í…Œê³ ë¦¬ ìŠ¤í¬ë˜í•‘: < 30ì´ˆ
- ìš”ì•½ ìƒì„±: < 20ì´ˆ
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: < 500MB
- API í˜¸ì¶œ ìµœì í™”: ë°°ì¹˜ ì²˜ë¦¬ ì§€ì›

## 10. ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

- API í‚¤ í™˜ê²½ ë³€ìˆ˜ ê´€ë¦¬
- ì›¹ ìŠ¤í¬ë˜í•‘ rate limiting ì¤€ìˆ˜
- User-Agent í—¤ë” ì ì ˆíˆ ì„¤ì •
- robots.txt ì¤€ìˆ˜

## 11. í™•ì¥ ê°€ëŠ¥ì„±

### í–¥í›„ ê°œì„  ì‚¬í•­

- ì‹¤ì‹œê°„ ì•Œë¦¼ ê¸°ëŠ¥
- ì‚¬ìš©ì ë§ì¶¤í˜• ì¹´í…Œê³ ë¦¬ ì„ íƒ
- ê°ì„± ë¶„ì„ ì¶”ê°€
- íŠ¸ë Œë“œ ë¶„ì„ ê¸°ëŠ¥
- ë‹¤êµ­ì–´ ì§€ì›
- ë‹¤ë¥¸ ë‰´ìŠ¤ ì†ŒìŠ¤ í†µí•©

## 12. ì„±ê³µ ì§€í‘œ

- ì¼ì¼ ìë™ ì‹¤í–‰ ì•ˆì •ì„± 99%+
- ë‰´ìŠ¤ ìš”ì•½ ì •í™•ë„ 90%+
- ì²˜ë¦¬ ì‹œê°„ ëª©í‘œ ë‹¬ì„±
- ì‚¬ìš©ì í”¼ë“œë°± ë°˜ì˜ ê°œì„ 

## 15. OpenAI API ì‚¬ìš© ì „ëµ

### 15.1 ëª¨ë¸ ì„ íƒ ê°€ì´ë“œ

| ìš©ë„             | ì¶”ì²œ ëª¨ë¸     | ì´ìœ                           |
| ---------------- | ------------- | ----------------------------- |
| ì¼ì¼ ì •ê¸° ìš”ì•½   | gpt-4o-mini   | ë¹„ìš© íš¨ìœ¨ì , ì¶©ë¶„í•œ ì„±ëŠ¥      |
| ì‹¬ì¸µ ë¶„ì„ í•„ìš”ì‹œ | gpt-4o        | ë†’ì€ ì •í™•ë„, ë³µì¡í•œ ë§¥ë½ ì´í•´ |
| í…ŒìŠ¤íŠ¸/ê°œë°œ      | gpt-3.5-turbo | ìµœì†Œ ë¹„ìš©                     |

### 15.2 í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿

```python
SUMMARY_PROMPT = """
ë‹¹ì‹ ì€ í•œêµ­ ë‰´ìŠ¤ ì „ë¬¸ ì—ë””í„°ì…ë‹ˆë‹¤.
ë‹¤ìŒ ë‰´ìŠ¤ ëª©ë¡ì„ ë¶„ì„í•˜ì—¬ Markdown í˜•ì‹ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.

ì¹´í…Œê³ ë¦¬: {category}
ë‰´ìŠ¤ ëª©ë¡:
{news_list}

ìš”êµ¬ì‚¬í•­:
1. ê°€ì¥ ì¤‘ìš”í•œ ë‰´ìŠ¤ 3-5ê°œ ì„ ë³„
2. ê° ë‰´ìŠ¤ëŠ” í•µì‹¬ ë‚´ìš©ì„ 2-3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½
3. ì¹´í…Œê³ ë¦¬ë³„ 'ì˜¤ëŠ˜ì˜ í¬ì¸íŠ¸' ì„¹ì…˜ ì¶”ê°€
4. Markdown í˜•ì‹ ì‚¬ìš© (ì œëª©ì€ ###, êµµì€ ê¸€ì”¨ëŠ” **)
5. ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ í™œìš©

ì¶œë ¥ í˜•ì‹:
### ì£¼ìš” ë‰´ìŠ¤
1. **[ë‰´ìŠ¤ ì œëª©]**
   - í•µì‹¬ ë‚´ìš© ìš”ì•½

### ì˜¤ëŠ˜ì˜ í¬ì¸íŠ¸
- ì „ì²´ì ì¸ íŠ¸ë Œë“œë‚˜ ì¤‘ìš” ì‹œì‚¬ì 
"""
```

### 15.3 API í˜¸ì¶œ ìµœì í™”

- ë°°ì¹˜ ì²˜ë¦¬: ì¹´í…Œê³ ë¦¬ë³„ ë¬¶ìŒ ìš”ì²­
- í† í° ì œí•œ: max_tokens=1000 per category
- ìºì‹±: 24ì‹œê°„ ë‚´ ë™ì¼ ë‰´ìŠ¤ ì¬ìš”ì•½ ë°©ì§€
- Rate Limiting: TPM/RPM ì œí•œ ì¤€ìˆ˜

## 16. ì˜ˆìƒ ë¹„ìš© ì‚°ì •

### 16.1 ì¼ì¼ ì²˜ë¦¬ëŸ‰ ê¸°ì¤€

- ì¹´í…Œê³ ë¦¬: 6ê°œ
- ì¹´í…Œê³ ë¦¬ë‹¹ ë‰´ìŠ¤: 10-15ê°œ
- ì…ë ¥ í† í°: ~2,000 tokens/category
- ì¶œë ¥ í† í°: ~500 tokens/category

### 16.2 ì›”ê°„ ì˜ˆìƒ ë¹„ìš©

| ëª¨ë¸        | ì¼ì¼ ë¹„ìš© | ì›”ê°„ ë¹„ìš© (30ì¼) |
| ----------- | --------- | ---------------- |
| gpt-4o-mini | ~$0.10    | ~$3.00           |
| gpt-4o      | ~$1.50    | ~$45.00          |

## 18. LangGraph 0.6+ êµ¬í˜„ ì˜ˆì œ

### 18.1 Graph ì´ˆê¸°í™” ë° ì‹¤í–‰

```python
# src/agents/graph.py
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import MemorySaver
from langgraph.prebuilt import ToolNode
from langchain_openai import ChatOpenAI
import asyncio

class NewsAgent:
    def __init__(self, openai_api_key: str):
        self.llm = ChatOpenAI(
            api_key=openai_api_key,
            model="gpt-4o-mini",
            temperature=0.3
        )
        self.graph = self._build_graph()

    def _build_graph(self) -> StateGraph:
        # ì›Œí¬í”Œë¡œìš° ìƒì„±
        workflow = StateGraph(NewsAgentState)

        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("scraper", self.scrape_news)
        workflow.add_node("summarizer", self.summarize_news)
        workflow.add_node("formatter", self.format_markdown)

        # ì—£ì§€ ì •ì˜
        workflow.add_edge(START, "scraper")
        workflow.add_edge("scraper", "summarizer")
        workflow.add_edge("summarizer", "formatter")
        workflow.add_edge("formatter", END)

        # ë©”ëª¨ë¦¬ì™€ í•¨ê»˜ ì»´íŒŒì¼
        memory = MemorySaver()
        return workflow.compile(checkpointer=memory)

    async def scrape_news(self, state: NewsAgentState):
        """ìŠ¤í¬ë˜í¼ ë…¸ë“œ êµ¬í˜„"""
        # ìŠ¤í¬ë˜í•‘ ë¡œì§
        return {"raw_news": scraped_data, "timestamp": datetime.now().isoformat()}

    async def summarize_news(self, state: NewsAgentState):
        """OpenAIë¥¼ ì‚¬ìš©í•œ ìš”ì•½ ë…¸ë“œ"""
        summaries = []
        for category_news in state["raw_news"]:
            response = await self.llm.ainvoke(
                SUMMARY_PROMPT.format(
                    category=category_news["category"],
                    news_list=category_news["articles"]
                )
            )
            summaries.append(response.content)
        return {"summaries": summaries}

    async def format_markdown(self, state: NewsAgentState):
        """ìµœì¢… ë§ˆí¬ë‹¤ìš´ ì¶œë ¥ í¬ë§·íŒ…"""
        # ë§ˆí¬ë‹¤ìš´ í¬ë§·íŒ… ë¡œì§
        return {"final_markdown": formatted_markdown}

    async def run(self):
        """ê·¸ë˜í”„ ì‹¤í–‰"""
        initial_state = {
            "categories": ["ì •ì¹˜", "ê²½ì œ", "ì‚¬íšŒ", "ìƒí™œ/ë¬¸í™”", "IT/ê³¼í•™", "ì„¸ê³„"],
            "raw_news": [],
            "summaries": [],
            "final_markdown": "",
            "messages": [],
            "errors": [],
            "timestamp": ""
        }

        # ì²´í¬í¬ì¸íŒ…ì„ ìœ„í•œ thread_idë¡œ ì‹¤í–‰
        config = {"configurable": {"thread_id": "news_thread_1"}}
        result = await self.graph.ainvoke(initial_state, config)
        return result["final_markdown"]
```

### 18.2 ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

```python
# src/main.py
import asyncio
from dotenv import load_dotenv
import os
from agents.graph import NewsAgent
from rich.console import Console
from rich.markdown import Markdown

async def main():
    load_dotenv()

    console = Console()

    # ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
    agent = NewsAgent(
        openai_api_key=os.getenv("OPENAI_API_KEY")
    )

    # ì—ì´ì „íŠ¸ ì‹¤í–‰
    console.print("[bold green]ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘...[/bold green]")
    markdown_result = await agent.run()

    # ê²°ê³¼ í‘œì‹œ
    md = Markdown(markdown_result)
    console.print(md)

    # íŒŒì¼ë¡œ ì €ì¥
    output_dir = os.getenv("OUTPUT_DIR", "./output/reports")
    os.makedirs(output_dir, exist_ok=True)

    filename = f"{output_dir}/{datetime.now().strftime('%Y-%m-%d')}_news.md"
    with open(filename, "w", encoding="utf-8") as f:
        f.write(markdown_result)

    console.print(f"[bold blue]ë¦¬í¬íŠ¸ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤[/bold blue]")

if __name__ == "__main__":
    asyncio.run(main())
```

### 18.3 LangGraph 0.6+ ì£¼ìš” ê¸°ëŠ¥ í™œìš©

#### ìŠ¤íŠ¸ë¦¬ë° ì§€ì›

```python
# ì¤‘ê°„ ê²°ê³¼ ìŠ¤íŠ¸ë¦¬ë°
async for chunk in app.astream(initial_state, config):
    print(f"ì²˜ë¦¬ ì¤‘: {chunk}")
```

#### ìƒíƒœ ì˜ì†ì„±

```python
# í”„ë¡œë•ì…˜ì—ì„œëŠ” SQLite ì‚¬ìš©
from langgraph.checkpoint.sqlite import SqliteSaver

checkpointer = SqliteSaver.from_conn_string("news_agent.db")
app = workflow.compile(checkpointer=checkpointer)
```

#### ì¡°ê±´ë¶€ ì—£ì§€

```python
def should_retry(state: NewsAgentState) -> str:
    # ì—ëŸ¬ê°€ ìˆìœ¼ë©´ ì¬ì‹œë„
    if len(state["errors"]) > 0:
        return "scraper"  # ìŠ¤í¬ë˜í•‘ ì¬ì‹œë„
    return "summarizer"  # ìš”ì•½ìœ¼ë¡œ ì§„í–‰

workflow.add_conditional_edges(
    "scraper",
    should_retry,
    {
        "scraper": "scraper",
        "summarizer": "summarizer"
    }
)
```

## 19. ì°¸ê³  ìë£Œ

- [LangGraph 0.6+ Documentation](https://github.com/langchain-ai/langgraph)
- [LangGraph Examples](https://github.com/langchain-ai/langgraph/tree/main/examples)
- [OpenAI API Documentation](https://platform.openai.com/docs)
- [uv Documentation](https://github.com/astral-sh/uv)
- [Naver News](https://news.naver.com)
